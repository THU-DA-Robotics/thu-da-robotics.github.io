---
---

@article{yu2024inhand,
  bibtex_show = {true},
  selected    = {true},
  preview     = {yu2024inhand.gif},
  arxiv       = {2403.12676},
  website     = {https://mingrui-yu.github.io/DLO_following/},
  title       = {In-Hand Following of Deformable Linear Objects Using Dexterous Fingers with Tactile Sensing},
  author      = {Yu, Mingrui and Liang, Boyuan and Zhang, Xiang and Zhu, Xinghao and Li, Xiang and Tomizuka, Masayoshi},
  journal     = {arXiv preprint arXiv:2403.12676},
  year        = {2024}
}

@misc{chen2024visual,
  bibtex_show   = {true},
  title         = {Visual Attention Based Cognitive Human--Robot Collaboration for Pedicle Screw Placement in Robot-Assisted Orthopedic Surgery},
  author        = {Chen Chen and Qikai Zou and Yuhang Song and Shiji Song and Xiang Li},
  year          = {2024},
  month         = {May},
  eprint        = {2405.09359},
  arxiv         = {2405.09359},
  archiveprefix = {arXiv},
  primaryclass  = {cs.RO},
  preview       = {chen2024visual.png},
  selected      = {true}
}

@article{yan2024complementary,
  bibtex_show = {true},
  selected    = {true},
  preview     = {yan2024complementary.png},
  author      = {Yan, Xiangjie and Jiang, Yongpeng and Chen, Chen and Gong, Leiliang and Ge, Ming and Zhang, Tao and Li, Xiang},
  journal     = {IEEE Transactions on Control Systems Technology},
  title       = {A Complementary Framework for Human–Robot Collaboration With a Mixed AR–Haptic Interface},
  year        = {2024},
  volume      = {32},
  number      = {1},
  pages       = {112-127},
  abstract    = {There is invariably a tradeoff between safety and efficiency for collaborative robots (cobots) in human–robot collaborations (HRCs). Robots that interact minimally with humans can work with high speed and accuracy but cannot adapt to new tasks or respond to unforeseen changes, whereas robots that work closely with humans can but only by becoming passive to humans, meaning that their main tasks are suspended and efficiency compromised. Accordingly, this article proposes a new complementary framework for HRC that balances the safety of humans and the efficiency of robots. In this framework, the robot carries out given tasks using a vision-based adaptive controller, and the human expert collaborates with the robot in the null space. Such a decoupling drives the robot to deal with existing issues in task space [e.g., uncalibrated camera, limited field of view (FOV)] and null space (e.g., joint limits) by itself while allowing the expert to adjust the configuration of the robot body to respond to unforeseen changes (e.g., sudden invasion, change in environment) without affecting the robot’s main task. In addition, the robot can simultaneously learn the expert’s demonstration in task space and null space beforehand with dynamic movement primitives (DMPs). Therefore, an expert’s knowledge and a robot’s capability are explored and complement each other. Human demonstration and involvement are enabled via a mixed interaction interface, i.e., augmented reality (AR) and haptic devices. The stability of the closed-loop system is rigorously proved with Lyapunov methods. Experimental results in various scenarios are presented to illustrate the performance of the proposed method.},
  doi         = {10.1109/TCST.2023.3301675},
  issn        = {1558-0865},
  month       = {Jan}
}

@article{yu2023generalizable,
  bibtex_show = {true},
  selected    = {true},
  preview     = {yu2023generalizable.gif},
  arxiv       = {2310.09899},
  website     = {https://mingrui-yu.github.io/DLO_planning_2/},
  title       = {Generalizable whole-body global manipulation of deformable linear objects by dual-arm robot in 3-D constrained environments},
  author      = {Yu, Mingrui and Lv, Kangchen and Wang, Changhao and Jiang, Yongpeng and Tomizuka, Masayoshi and Li, Xiang},
  journal     = {arXiv preprint arXiv:2310.09899},
  year        = {2023}
}

@article{yu2023global,
  bibtex_show = {true},
  selected    = {true},
  preview     = {yu2023global.gif},
  arxiv       = {2205.04004},
  website     = {https://mingrui-yu.github.io/shape_control_DLO_2/},
  code        = {https://github.com/Mingrui-Yu/shape_control_DLO_2},
  author      = {Yu, Mingrui and Lv, Kangchen and Zhong, Hanzhong and Song, Shiji and Li, Xiang},
  journal     = {IEEE Transactions on Robotics},
  title       = {Global Model Learning for Large Deformation Control of Elastic Deformable Linear Objects: An Efficient and Adaptive Approach},
  year        = {2023},
  volume      = {39},
  number      = {1},
  pages       = {417-436},
  doi         = {10.1109/TRO.2022.3200546}
}

@inproceedings{yu2023acoarse,
  bibtex_show = {true},
  selected    = {true},
  preview     = {yu2023acoarse.gif},
  arxiv       = {2209.11145},
  website     = {https://mingrui-yu.github.io/DLO_planning/},
  author      = {Yu, Mingrui and Lv, Kangchen and Wang, Changhao and Tomizuka, Masayoshi and Li, Xiang},
  booktitle   = {2023 IEEE International Conference on Robotics and Automation (ICRA)},
  title       = {A Coarse-to-Fine Framework for Dual-Arm Manipulation of Deformable Linear Objects with Whole-Body Obstacle Avoidance},
  year        = {2023},
  pages       = {10153-10159},
  doi         = {10.1109/ICRA48891.2023.10160264}
}

@inproceedings{lv2023learning,
  bibtex_show = {true},
  selected    = {true},
  preview     = {lv2023learning.gif},
  arxiv       = {2210.01433},
  author      = {Lv, Kangchen and Yu, Mingrui and Pu, Yifan and Jiang, Xin and Huang, Gao and Li, Xiang},
  booktitle   = {2023 IEEE International Conference on Robotics and Automation (ICRA)},
  title       = {Learning to Estimate 3-D States of Deformable Linear Objects from Single-Frame Occluded Point Clouds},
  year        = {2023},
  volume      = {},
  number      = {},
  pages       = {7119-7125},
  keywords    = {Point cloud compression;Learning systems;Geometry;Solid modeling;Automation;Shape;Wires},
  doi         = {10.1109/ICRA48891.2023.10160784}
}


@inproceedings{yan2022adaptive,
  bibtex_show = {true},
  author      = {Yan, Xiangjie and Chen, Chen and Li, Xiang},
  booktitle   = {2022 International Conference on Robotics and Automation (ICRA)},
  title       = {Adaptive Vision-Based Control of Redundant Robots with Null-Space Interaction for Human-Robot Collaboration},
  year        = {2022},
  pages       = {2803-2809},
  abstract    = {Human-robot collaboration aims to extend human ability through cooperation with robots. This technology is currently helping people with physical disabilities, has transformed the manufacturing process of companies, improved surgical performance, and will likely revolutionize the daily lives of everyone in the future. Being able to enhance the performance of both sides, such that human-robot collaboration outperforms a single robot/human, remains an open issue. For safer and more effective collaboration, a new control scheme has been proposed for redundant robots in this paper, consisting of an adaptive vision-based control term in task space and an interactive control term in null space. Such a formulation allows the robot to autonomously carry out tasks in an unknown environment without prior calibration while also interacting with humans to deal with unforeseen changes (e.g., potential collision, temporary needs) under the redundant configuration. The decoupling between task space and null space helps to explore the collaboration safely and effectively without affecting the main task of the robot end-effector. The stability of the closed-loop system has been rigorously proved with Lyapunov methods, and both the convergence of the position error in task space and that of the damping model in null space are guaranteed. The experimental results of a robot manipulator guided with the technology of augmented reality (AR) are presented to illustrate the performance of the control scheme.},
  doi         = {10.1109/ICRA46639.2022.9812218},
  code        = {https://github.com/yanseim/Vision-Based-Control},
  month       = {May},
  selected    = {true},
  preview     = {yan2022adaptive.jpeg}
}

@misc{yan2023multimodal,
  bibtex_show   = {true},
  title         = {Multi-Modal Interaction Control of Ultrasound Scanning Robots with Safe Human Guidance and Contact Recovery},
  author        = {Xiangjie Yan and Yongpeng Jiang and Guokun Wu and Chen Chen and Gao Huang and Xiang Li},
  year          = {2023},
  month         = {Feb},
  eprint        = {2302.05685},
  arxiv         = {2302.05685},
  archiveprefix = {arXiv},
  primaryclass  = {cs.RO},
  preview       = {yan2023multimodal.png}
}

@inproceedings{yu2022shape,
  bibtex_show = {true},
  selected    = {true},
  preview     = {yu2022shape.gif},
  arxiv       = {2109.11091},
  website     = {https://mingrui-yu.github.io/shape_control_DLO/},
  code        = {https://github.com/Mingrui-Yu/shape_control_DLO},
  author      = {Yu, Mingrui and Zhong, Hanzhong and Li, Xiang},
  booktitle   = {2022 International Conference on Robotics and Automation (ICRA)},
  title       = {Shape Control of Deformable Linear Objects with Offline and Online Learning of Local Linear Deformation Models},
  year        = {2022},
  volume      = {},
  number      = {},
  pages       = {1337-1343},
  doi         = {10.1109/ICRA46639.2022.9812244}
}

@inproceedings{jiang2023contact,
  bibtex_show = {true},
  selected    = {true},
  preview     = {jiang2023contact.png},
  arxiv       = {2303.03635},
  website     = {https://director-of-g.github.io/push_in_clutter/},
  author      = {Yongpeng Jiang and Yongyi Jia and Xiang Li},
  booktitle   = {2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title       = {Contact-Aware Non-prehensile Robotic Manipulation for Object Retrieval in Cluttered Environments},
  year        = {2023},
  volume      = {},
  number      = {},
  pages       = {10604-10611},
  doi         = {10.1109/IROS55552.2023.10341476}
}

@misc{jiang2024contact,
  bibtex_show   = {true},
  preview       = {jiang2024contact.png},
  website       = {https://director-of-g.github.io/in_hand_manipulation/},
  title         = {Contact-Implicit Model Predictive Control for Dexterous In-hand Manipulation: A Long-Horizon and Robust Approach},
  author        = {Yongpeng Jiang and Mingrui Yu and Xinghao Zhu and Masayoshi Tomizuka and Xiang Li},
  year          = {2024},
  month         = {Feb},
  eprint        = {2402.18897},
  arxiv         = {2402.18897},
  archiveprefix = {arXiv},
  primaryclass  = {cs.RO},
  selected      = {true}
}
